{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a458bebc",
   "metadata": {},
   "source": [
    "## Graph Attention Network (GAT)\n",
    "\n",
    "### Importing Dependencies\n",
    "\n",
    "We import the necessary libraries and functions, ensuring that all required modules and helper functions are properly integrated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58fe2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# gat → models → src\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "\n",
    "import import_ipynb \n",
    "from utils.wrapper.networkx_to_pyg import networkx_to_pyg\n",
    "from utils.add_dummy_node_features import add_dummy_node_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98755922",
   "metadata": {},
   "source": [
    "### Loading and Preparing Graph Data from GraphML Files\n",
    "\n",
    "This code snippet loads a series of bicycle traffic network graphs stored in GraphML format and prepares them for training with PyTorch Geometric (PyG). The objective is to convert each monthly graph into a format compatible with Graph Neural Networks (GNNs), ensuring that edge features are retained.\n",
    "\n",
    "Each NetworkX graph is converted into a PyG `Data` object using a custom helper function `networkx_to_pyg`. This function ensures that essential edge attributes such as:\n",
    "\n",
    "- `tracks` (the number of bicycles traveling from the starting to the ending point),\n",
    "- `month` and `year`,\n",
    "- `speed_rel` (relative speed),\n",
    "\n",
    "are preserved during the conversion process.\n",
    "\n",
    "PyG expects data in a specific structure, particularly when edge attributes are used in models like GATv2.\n",
    "\n",
    "`data_list` contains multiple `torch_geometric.data.Data` objects, each representing a graph.\n",
    "\n",
    "**NOTE:** So far I only did for data from 2023. I will iterate through all available data, when the implementation is finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731c66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store the PyTorch Geometric Data objects\n",
    "data_list = []\n",
    "\n",
    "# Iterate over the 12 graph files (from 0 to 11)\n",
    "for i in range(12):  # 0 to 11\n",
    "    # Build the path to the graph file\n",
    "    path = f\"../../../graphs/2023/bike_network_2023_{i}.graphml\"\n",
    "    \n",
    "    # Read the graph from the GraphML file\n",
    "    G_nx = nx.read_graphml(path)\n",
    "    \n",
    "    # Ensure the graph is loaded as a directed graph (DiGraph)\n",
    "    G_nx = nx.DiGraph(G_nx)\n",
    "    \n",
    "    # Use the custom function to convert the NetworkX graph to a PyTorch Geometric Data object\n",
    "    # The edge attributes (such as 'tracks', 'month', 'year', 'speed_rel') will be preserved\n",
    "    data = networkx_to_pyg(G_nx)\n",
    "    \n",
    "    # Append the Data object to the list\n",
    "    data_list.append(data)\n",
    "\n",
    "# Check the result - number of graphs (Data objects) loaded\n",
    "print(f\"Number of graphs: {len(data_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d10c2e",
   "metadata": {},
   "source": [
    "### Adding Dummy Node Features to the Graphs\n",
    "\n",
    "In this section of the code, we add **dummy node features** to our graphs. This process ensures that each node in our graphs has a **feature dimension**, even if no node features were originally present. This is an important step in preparing the data for use in Graph Neural Networks (GNNs).\n",
    "\n",
    "**NOTE:** At a later stage, once we have implemented feature engineering, we will replace the dummy features with the engineered ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c85152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = add_dummy_node_features(data_list, feature_dim=1, value=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2dd7ab",
   "metadata": {},
   "source": [
    "### Train-Validation Split\n",
    "\n",
    "For predicting edge attributes (e.g., `tracks`), an 80/20 train/validation split was applied to the **existing edges within each graph**.\n",
    "\n",
    "In our application, the **nodes represent physically existing bike stations**, which typically do not change or only change very infrequently. The aim of the analysis is to model the **connections between stations**, i.e., to understand and predict how many bicycles move along certain routes (in other words: edges with weights).\n",
    "\n",
    "A **node-level split** (i.e., an 80/20 split of the nodes themselves) would mean that some stations would be completely unseen during training. This would not be meaningful because:\n",
    "\n",
    "- The **stations themselves are not the prediction target**;\n",
    "- It is the **relationships or transitions between the stations (edges)** that should be modeled;\n",
    "- In deployment, **all stations are known** (they are physically installed in the system);\n",
    "\n",
    "**NOTE:** GCN and GCN-GRU could also use these functions. So we would move them to the folder utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf90480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 0:\n",
      "  Train edges: 16671\n",
      "  Val edges:   8334\n",
      "Graph 1:\n",
      "  Train edges: 17980\n",
      "  Val edges:   8988\n",
      "Graph 2:\n",
      "  Train edges: 18066\n",
      "  Val edges:   9032\n",
      "Graph 3:\n",
      "  Train edges: 22253\n",
      "  Val edges:   11126\n",
      "Graph 4:\n",
      "  Train edges: 26821\n",
      "  Val edges:   13410\n",
      "Graph 5:\n",
      "  Train edges: 38612\n",
      "  Val edges:   19304\n",
      "Graph 6:\n",
      "  Train edges: 31458\n",
      "  Val edges:   15728\n",
      "Graph 7:\n",
      "  Train edges: 30864\n",
      "  Val edges:   15432\n",
      "Graph 8:\n",
      "  Train edges: 30796\n",
      "  Val edges:   15396\n",
      "Graph 9:\n",
      "  Train edges: 24759\n",
      "  Val edges:   12378\n",
      "Graph 10:\n",
      "  Train edges: 19477\n",
      "  Val edges:   9738\n",
      "Graph 11:\n",
      "  Train edges: 14930\n",
      "  Val edges:   7464\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# Define the 80/20 train/val split\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.2,  # 20% for validation\n",
    "    num_test=0.0,  # no test set (test set will be 2024 data)\n",
    "    is_undirected=False,  # Set to False if your graphs are directed\n",
    "    split_labels=False,\n",
    ")\n",
    "\n",
    "# Apply the transform to each graph in your list\n",
    "train_val_data_list = [transform(data) for data in data_list]\n",
    "\n",
    "# Now you get a list of (train_data, val_data) tuples\n",
    "for i, (train_data, val_data, _) in enumerate(train_val_data_list):\n",
    "    print(f\"Graph {i}:\")\n",
    "    print(f\"  Train edges: {train_data.edge_index.size(1)}\")\n",
    "    print(f\"  Val edges:   {val_data.edge_label_index.size(1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd348f6d",
   "metadata": {},
   "source": [
    "### Implementing a GAT Model\n",
    "\n",
    "We implement the **Graph Attention Network (GATv2)** model, an advanced model for Graph Neural Networks (GNNs) that is based on the principles of **attention mechanisms**. It is specifically designed to aggregate node features while learning the relationships between nodes, taking into account **edge attributes**.\n",
    "\n",
    "The GATv2 model expects the following **input**:\n",
    "- `x`: Node features → `data.x`\n",
    "- `edge_index`: Edge list → `data.edge_index`\n",
    "- `edge_attr`: Edge attributes → `data.edge_attr`\n",
    "\n",
    "These values are passed from the `Data` object when calling your model.\n",
    "\n",
    "**Output**: The model currently returns node representations (node embeddings) – a tensor with one row per node and one column per feature at the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a77b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, heads=1):\n",
    "        super(GATv2, self).__init__()\n",
    "\n",
    "        # First GATv2 layer, with edge attributes\n",
    "        self.gat1 = GATv2Conv(in_channels, hidden_channels, heads=heads, edge_dim=edge_dim)\n",
    "\n",
    "        # Second GATv2 layer, output dimension = out_channels\n",
    "        self.gat2 = GATv2Conv(hidden_channels * heads, out_channels, heads=1, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply first GATv2 layer with edge attributes\n",
    "        x = self.gat1(x, edge_index, edge_attr)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        # Apply second GATv2 layer\n",
    "        x = self.gat2(x, edge_index, edge_attr)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517e9d4",
   "metadata": {},
   "source": [
    "### Advancing to Encoder-Decoder Architecture\n",
    "\n",
    "As we can see, the original GATv2 model is primarily designed to learn **node representations (node embeddings)**. These embeddings are well-suited for tasks like node classification, but they are **not directly applicable for predicting edge attributes** – such as our target edge weight `tracks`.\n",
    "\n",
    "Since our goal is to **predict edge values**, a pure node embedding model is not sufficient. Therefore, we extend the GATv2 model by adding an **additional layer** that takes the computed node embeddings and produces a prediction for each edge.\n",
    "\n",
    "Our final model follows the common **encoder-decoder architecture**:\n",
    "\n",
    "- **Encoder:**  \n",
    "  - We use the GATv2 model as an encoder to compute **informative node embeddings** from the input node features, graph structure, and edge attributes.\n",
    "\n",
    "- **Decoder:**  \n",
    "  - As a decoder, we use a **small multilayer perceptron (MLP)** that combines the embeddings of each edge's source and target node (via concatenation).  \n",
    "  - This MLP then outputs a **single scalar per edge** – which serves as our prediction for the edge weight `tracks`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2e4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GATv2EdgePredictor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 hidden_channels, \n",
    "                 out_channels, \n",
    "                 edge_dim, \n",
    "                 heads=1):\n",
    "        super(GATv2EdgePredictor, self).__init__()\n",
    "\n",
    "        # 1. GATv2 model for computing node embeddings\n",
    "        self.gnn = GATv2(in_channels, hidden_channels, out_channels, edge_dim, heads)\n",
    "\n",
    "        # 2. Edge MLP to predict edge attributes (e.g., \"tracks\")\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, 1)  # Output: a single scalar per edge\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: PyTorch Geometric Data object with attributes:\n",
    "                  - x: node features\n",
    "                  - edge_index: edge connectivity (COO format)\n",
    "                  - edge_attr: edge attributes\n",
    "\n",
    "        Returns:\n",
    "            pred: Tensor of shape [num_edges, 1] with predicted edge weights (e.g., \"tracks\")\n",
    "        \"\"\"\n",
    "        # Compute node embeddings using the GATv2 model\n",
    "        x = self.gnn(data.x, data.edge_index, data.edge_attr)  # [num_nodes, out_channels]\n",
    "\n",
    "        # Construct edge representations by concatenating source and target node embeddings\n",
    "        row, col = data.edge_index  # source & target node indices for each edge\n",
    "        edge_inputs = torch.cat([x[row], x[col]], dim=1)  # [num_edges, out_channels * 2]\n",
    "\n",
    "        # Predict edge weights\n",
    "        pred = self.edge_mlp(edge_inputs)  # [num_edges, 1]\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd4f8a",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "- **in_channels=1**: In our setup, we used the `add_dummy_node_features(...)` function, which adds dummy features with one dimension to all nodes. **NOTE:** This will be adjusted later once we implement additional feature engineering.\n",
    "\n",
    "- **head=1**: Initially, we keet the model simple by using one attention head. With multiple heads, the embeddings would need to be concatenated or averaged later. I assume, if we change this, we will also need to adjust the dimensions accordingly. \n",
    "\n",
    "- **hidden_channels=32 / out_channels=32**: We chose 32 to strike a good balance between computational cost and model capacity.\n",
    "\n",
    "- **Adam**: A very popular optimization algorithm. The learning rate is a sensitive hyperparameter, and 0.01 is a solid starting value. \n",
    "\n",
    "- **MSELoss**: We use Mean Squared Error (MSE) Loss as the loss function since the edge weight prediction is a regression problem. We might also try using L1 Loss.\n",
    "\n",
    "**NOTE:** We may later perform hyperparameter optimization (HPO) on hyperparameters such as the learning rate using random search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2fa65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized, loss function and optimizer defined.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Initialize the model (adjust input values as needed)\n",
    "model = GATv2EdgePredictor(\n",
    "    in_channels=1,                     # Number of input node features (e.g., data.num_node_features)\n",
    "    hidden_channels=32,                # Size of hidden representations\n",
    "    out_channels=32,                   # Output size of node embeddings\n",
    "    edge_dim=data.edge_attr.shape[1],  # Dimensionality of edge attributes\n",
    "    heads=1                            # Number of attention heads\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = MSELoss()                          # Mean Squared Error for regression\n",
    "optimizer = Adam(model.parameters(), lr=0.01)  # Adam optimizer with learning rate 0.01\n",
    "\n",
    "print(\"Model initialized, loss function and optimizer defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef1285",
   "metadata": {},
   "source": [
    "### Training and Validation Loop\n",
    "\n",
    "We implemented **early stopping** to prevent overfitting and unnecessary training time. The mechanism works as follows: If the validation loss improves during an epoch, the model parameters are saved, and the counter for epochs without improvement is reset to `0`. If no improvement is observed for the specified number of epochs (`early_stopping_patience`), training is stopped early, and the best model is returned.\n",
    "\n",
    "- **Consider switching to minibatches**: In the future, we might switch to using minibatches to increase training efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2001e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Training Loss: 333.0140\n",
      "Epoch 010 | Training Loss: 257.1412\n",
      "Epoch 020 | Training Loss: 197.2691\n",
      "Epoch 030 | Training Loss: 197.4322\n",
      "Epoch 040 | Training Loss: 195.1697\n",
      "Epoch 050 | Training Loss: 194.9637\n",
      "Epoch 050 | Validation Loss: 194.9500\n",
      "Epoch 060 | Training Loss: 194.9608\n",
      "Epoch 070 | Training Loss: 194.9910\n",
      "Epoch 080 | Training Loss: 194.9718\n",
      "Epoch 090 | Training Loss: 194.9391\n",
      "Epoch 100 | Training Loss: 194.9320\n",
      "Epoch 100 | Validation Loss: 194.9332\n",
      "Epoch 110 | Training Loss: 194.9335\n",
      "Epoch 120 | Training Loss: 194.9322\n",
      "Epoch 130 | Training Loss: 194.9319\n",
      "Epoch 140 | Training Loss: 194.9319\n",
      "Epoch 150 | Training Loss: 194.9319\n",
      "Epoch 150 | Validation Loss: 194.9319\n",
      "Epoch 160 | Training Loss: 194.9319\n",
      "Epoch 170 | Training Loss: 194.9319\n",
      "Epoch 180 | Training Loss: 194.9319\n",
      "Epoch 190 | Training Loss: 194.9319\n",
      "Epoch 200 | Training Loss: 194.9319\n",
      "Epoch 200 | Validation Loss: 194.9319\n",
      "Epoch 210 | Training Loss: 194.9319\n",
      "Epoch 220 | Training Loss: 194.9319\n",
      "Epoch 230 | Training Loss: 194.9319\n",
      "Epoch 240 | Training Loss: 194.9319\n",
      "Epoch 250 | Training Loss: 194.9319\n",
      "Epoch 250 | Validation Loss: 194.9319\n",
      "Epoch 260 | Training Loss: 194.9319\n",
      "Epoch 270 | Training Loss: 194.9319\n",
      "Epoch 280 | Training Loss: 194.9319\n",
      "Epoch 290 | Training Loss: 194.9319\n",
      "Epoch 300 | Training Loss: 194.9319\n",
      "Epoch 300 | Validation Loss: 194.9319\n",
      "Epoch 310 | Training Loss: 194.9319\n",
      "Epoch 320 | Training Loss: 194.9319\n",
      "Epoch 330 | Training Loss: 194.9319\n",
      "Epoch 340 | Training Loss: 194.9319\n",
      "Epoch 350 | Training Loss: 194.9319\n",
      "Epoch 350 | Validation Loss: 194.9319\n",
      "Epoch 360 | Training Loss: 194.9319\n",
      "Epoch 370 | Training Loss: 194.9319\n",
      "Epoch 380 | Training Loss: 194.9319\n",
      "Epoch 390 | Training Loss: 194.9319\n",
      "Epoch 400 | Training Loss: 194.9319\n",
      "Epoch 400 | Validation Loss: 194.9319\n",
      "Epoch 410 | Training Loss: 194.9319\n",
      "Epoch 420 | Training Loss: 194.9319\n",
      "Epoch 430 | Training Loss: 194.9319\n",
      "Epoch 440 | Training Loss: 194.9319\n",
      "Epoch 450 | Training Loss: 194.9319\n",
      "Epoch 450 | Validation Loss: 194.9319\n",
      "Epoch 460 | Training Loss: 194.9319\n",
      "Epoch 470 | Training Loss: 194.9319\n",
      "Epoch 480 | Training Loss: 194.9319\n",
      "Epoch 490 | Training Loss: 194.9319\n",
      "Epoch 500 | Training Loss: 194.9319\n",
      "Epoch 500 | Validation Loss: 194.9319\n",
      "Epoch 510 | Training Loss: 194.9319\n",
      "Epoch 520 | Training Loss: 194.9319\n",
      "Epoch 530 | Training Loss: 194.9319\n",
      "Epoch 540 | Training Loss: 194.9319\n",
      "Epoch 550 | Training Loss: 194.9319\n",
      "Epoch 550 | Validation Loss: 194.9319\n",
      "Epoch 560 | Training Loss: 194.9319\n",
      "Epoch 570 | Training Loss: 194.9319\n",
      "Epoch 580 | Training Loss: 194.9319\n",
      "Epoch 590 | Training Loss: 194.9319\n",
      "Epoch 600 | Training Loss: 194.9319\n",
      "Epoch 600 | Validation Loss: 194.9319\n",
      "Epoch 610 | Training Loss: 194.9319\n",
      "Epoch 620 | Training Loss: 194.9319\n",
      "Epoch 630 | Training Loss: 194.9319\n",
      "Epoch 640 | Training Loss: 194.9319\n",
      "Epoch 650 | Training Loss: 194.9319\n",
      "Epoch 650 | Validation Loss: 194.9319\n",
      "Epoch 660 | Training Loss: 194.9319\n",
      "Epoch 670 | Training Loss: 194.9319\n",
      "Epoch 680 | Training Loss: 194.9319\n",
      "Epoch 690 | Training Loss: 194.9319\n",
      "Epoch 700 | Training Loss: 194.9319\n",
      "Epoch 700 | Validation Loss: 194.9319\n",
      "Epoch 710 | Training Loss: 194.9319\n",
      "Epoch 720 | Training Loss: 194.9319\n",
      "Epoch 730 | Training Loss: 194.9319\n",
      "Epoch 740 | Training Loss: 194.9319\n",
      "Epoch 750 | Training Loss: 194.9319\n",
      "Epoch 750 | Validation Loss: 194.9319\n",
      "Epoch 760 | Training Loss: 194.9319\n",
      "Epoch 770 | Training Loss: 194.9319\n",
      "Epoch 780 | Training Loss: 194.9319\n",
      "Epoch 790 | Training Loss: 194.9319\n",
      "Epoch 800 | Training Loss: 194.9319\n",
      "Epoch 800 | Validation Loss: 194.9319\n",
      "Epoch 810 | Training Loss: 194.9319\n",
      "Epoch 820 | Training Loss: 194.9319\n",
      "Epoch 830 | Training Loss: 194.9319\n",
      "Epoch 840 | Training Loss: 194.9319\n",
      "Epoch 850 | Training Loss: 194.9319\n",
      "Epoch 850 | Validation Loss: 194.9319\n",
      "Epoch 860 | Training Loss: 194.9319\n",
      "Epoch 870 | Training Loss: 194.9319\n",
      "Epoch 880 | Training Loss: 194.9319\n",
      "Epoch 890 | Training Loss: 194.9319\n",
      "Epoch 900 | Training Loss: 194.9319\n",
      "Epoch 900 | Validation Loss: 194.9319\n",
      "Epoch 910 | Training Loss: 194.9319\n",
      "Epoch 920 | Training Loss: 194.9319\n",
      "Epoch 930 | Training Loss: 194.9319\n",
      "Epoch 940 | Training Loss: 194.9319\n",
      "Epoch 950 | Training Loss: 194.9319\n",
      "Epoch 950 | Validation Loss: 194.9319\n",
      "Epoch 960 | Training Loss: 194.9319\n",
      "Epoch 970 | Training Loss: 194.9319\n",
      "Epoch 980 | Training Loss: 194.9319\n",
      "Epoch 990 | Training Loss: 194.9319\n",
      "Epoch 1000 | Training Loss: 194.9319\n",
      "Epoch 1000 | Validation Loss: 194.9319\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "early_stopping_patience = 10  # How many epochs to wait before stopping if no improvement occurs\n",
    "best_val_loss = float('inf')  # Initialize with a very high value\n",
    "epochs_without_improvement = 0  # Counter for epochs without improvement\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass: predict edge values\n",
    "    pred = model(train_data)  # Shape: [num_edges, 1]\n",
    "\n",
    "    # Ground truth edge weights (e.g., 'tracks' value assumed to be the first attribute)\n",
    "    target = train_data.edge_attr[:, 4].unsqueeze(1)  # Ensure shape matches prediction [num_edges, 1]\n",
    "\n",
    "    # Compute loss between predictions and ground truth\n",
    "    loss = criterion(pred, target)\n",
    "\n",
    "    # Backpropagation and parameter update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging progress every 10 epochs (training loss)\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:03d} | Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Validation every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            val_pred = model(val_data)  # Validation data\n",
    "            val_target = val_data.edge_attr[:, 4].unsqueeze(1)\n",
    "            val_loss = criterion(val_pred, val_target)\n",
    "\n",
    "        # Logging progress for validation loss every 50 epochs\n",
    "        print(f\"Epoch {epoch:03d} | Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        # Early stopping check: if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  # Update best validation loss\n",
    "            epochs_without_improvement = 0  # Reset the counter\n",
    "            # Save the model when improvement occurs\n",
    "            torch.save(model.state_dict(), 'best_model/best_model.pth')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # If no improvement for 'early_stopping_patience' epochs, stop training\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
