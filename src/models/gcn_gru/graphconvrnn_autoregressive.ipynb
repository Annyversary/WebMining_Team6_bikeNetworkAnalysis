{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66b5123",
   "metadata": {},
   "source": [
    "# üìà Autoregressive 12-Monats-Vorhersage mit GraphConvRNN\n",
    "Dieses Notebook trainiert ein GraphConvRNN-Modell auf 2021-2022, validiert auf 2023 und sagt die Kanten-Gewichte f√ºr alle Monate 2024 voraus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6a0c0",
   "metadata": {},
   "source": [
    "## 1. üì¶ Installieren und importieren"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import DataLoader, Batch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:07.088999Z",
     "start_time": "2025-04-26T17:41:06.968156Z"
    }
   },
   "id": "f73c3dfc0e5623ea",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. üèóÔ∏è Definition von GraphConvRNN mit Hidden State"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d8fd586f2f670a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GraphConvRNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, rnn_layers=1):\n",
    "        super().__init__()\n",
    "        self.gcn = GCNConv(in_channels, hidden_channels)\n",
    "        self.gru = nn.GRU(hidden_channels, hidden_channels, rnn_layers, batch_first=True)\n",
    "        self.edge_mlp = nn.Linear(hidden_channels, out_channels)  # NEU: f√ºr Kanten\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, hidden=None):\n",
    "        # GCN-Schicht\n",
    "        x = self.gcn(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Zeitliche Sequenz\n",
    "        x_seq = x.unsqueeze(0)  # [1, num_nodes, hidden_dim]\n",
    "        out_seq, hidden = self.gru(x_seq, hidden)\n",
    "        node_embeddings = out_seq.squeeze(0)  # [num_nodes, hidden_dim]\n",
    "\n",
    "        # ‚ûî Wichtig: Erzeuge Kantenrepr√§sentationen\n",
    "        source, target = edge_index\n",
    "        edge_embeddings = (node_embeddings[source] + node_embeddings[target]) / 2\n",
    "\n",
    "        # MLP auf Kanten\n",
    "        edge_output = self.edge_mlp(edge_embeddings)\n",
    "        \n",
    "        return edge_output.squeeze(), hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:41:07.275629Z",
     "start_time": "2025-04-26T17:41:07.262978Z"
    }
   },
   "id": "1c1da82984bce094",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. üóÇÔ∏è Daten laden und vorbereiten"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e6cbdb302794626"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funktion um GraphML-Dateien zu laden\n",
    "def load_graphml(year):\n",
    "    files = glob.glob(f'../../../data/graphml/{year}/*.graphml')\n",
    "    data_list = []\n",
    "    for f in sorted(files):\n",
    "        G = nx.read_graphml(f)\n",
    "        data = from_networkx(G, group_node_attrs=['lat', 'lon'], group_edge_attrs=['id','month','speed_rel','tracks','year'])\n",
    "        data.y = data.edge_attr[:,3]\n",
    "        data.edge_attr = torch.cat([data.edge_attr[:,:3], data.edge_attr[:,4:]], dim=1)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "train_list = load_graphml(2021) + load_graphml(2022)\n",
    "val_list = load_graphml(2023)\n",
    "test_list = load_graphml(2024)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:43:46.842546Z",
     "start_time": "2025-04-26T17:41:07.285023Z"
    }
   },
   "id": "8e211a606c36590e",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. ‚öôÔ∏è Dataloader f√ºr Training und Validierung"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a693c65e7e663c1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiede\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_list, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_list, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:43:46.854427Z",
     "start_time": "2025-04-26T17:43:46.845558Z"
    }
   },
   "id": "f556478262d015a2",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. üß† Modell, Optimizer und Loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87d3dfb6a4728986"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphConvRNN(\n",
    "    in_channels=train_list[0].num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=1\n",
    ").to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\" Root Mean Squared Error \"\"\"\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2)).item()\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\" Mean Absolute Percentage Error \"\"\"\n",
    "    # Hinzuf√ºgen eines kleinen Terms (epsilon), um Division durch Null zu vermeiden\n",
    "    epsilon = 1e-8\n",
    "    return (torch.mean(torch.abs((y_true - y_pred) / (y_true + epsilon))) * 100).item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:43:46.876583Z",
     "start_time": "2025-04-26T17:43:46.857527Z"
    }
   },
   "id": "6021ed2e4142532d",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. üîç Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d91219c29fb82d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     27\u001B[39m         out, _ = model(data.x, data.edge_index, data.edge_attr)\n\u001B[32m     28\u001B[39m         loss = criterion(out.view(-\u001B[32m1\u001B[39m), data.y.view(-\u001B[32m1\u001B[39m))\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m         \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m         optimizer.step()\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Validation\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:570\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    567\u001B[39m     \u001B[38;5;66;03m# All strings are unicode in Python 3.\u001B[39;00m\n\u001B[32m    568\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m torch._tensor_str._str(\u001B[38;5;28mself\u001B[39m, tensor_contents=tensor_contents)\n\u001B[32m--> \u001B[39m\u001B[32m570\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mbackward\u001B[39m(\n\u001B[32m    571\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient=\u001B[38;5;28;01mNone\u001B[39;00m, retain_graph=\u001B[38;5;28;01mNone\u001B[39;00m, create_graph=\u001B[38;5;28;01mFalse\u001B[39;00m, inputs=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    572\u001B[39m ):\n\u001B[32m    573\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001B[39;00m\n\u001B[32m    574\u001B[39m \n\u001B[32m    575\u001B[39m \u001B[33;03m    The graph is differentiated using the chain rule. If the tensor is\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    614\u001B[39m \u001B[33;03m            used to compute the :attr:`tensors`.\u001B[39;00m\n\u001B[32m    615\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tsl.metrics.numpy.functional import rmse, mape\n",
    "import numpy as np\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_rmse = float('inf')\n",
    "best_val_mape = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for lr in [1e-3, 5e-4]:\n",
    "    for wd in [0, 1e-5]:\n",
    "        # Modell neu initialisieren f√ºr jede Kombi (wichtig!)\n",
    "        model = GraphConvRNN(\n",
    "            in_channels=train_list[0].num_node_features,\n",
    "            hidden_channels=64,\n",
    "            out_channels=1\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        \n",
    "        # Training\n",
    "        for epoch in range(1, 21):\n",
    "            model.train()\n",
    "            for data in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out, _ = model(data.x, data.edge_index, data.edge_attr)\n",
    "                loss = criterion(out.view(-1), data.y.view(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                out, _ = model(data.x, data.edge_index, data.edge_attr)\n",
    "                y_true_all.append(data.y.view(-1).cpu().numpy())\n",
    "                y_pred_all.append(out.view(-1).cpu().numpy())\n",
    "                val_loss += criterion(out.view(-1), data.y.view(-1)).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # RMSE und MAPE mit NumPy\n",
    "        y_true_all = np.concatenate(y_true_all)\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "        \n",
    "        val_rmse = rmse(y_pred_all, y_true_all)\n",
    "        val_mape = mape(y_pred_all, y_true_all)\n",
    "\n",
    "        # Beste Hyperparameter aktualisieren, wenn bessere Validierung\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_rmse = val_rmse\n",
    "            best_val_mape = val_mape\n",
    "            best_params = {\n",
    "                'lr': lr,\n",
    "                'weight_decay': wd,\n",
    "                'val_loss': best_val_loss,\n",
    "                'val_rmse': best_val_rmse,\n",
    "                'val_mape': best_val_mape\n",
    "            }\n",
    "\n",
    "# Speichern der besten Kombination als JSON\n",
    "with open('best_hyperparams.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "\n",
    "print('Beste Hyperparameter gefunden:')\n",
    "print(json.dumps(best_params, indent=4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T17:47:39.265092Z",
     "start_time": "2025-04-26T17:43:46.881102Z"
    }
   },
   "id": "a56feed984c2c252",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. üèãÔ∏è Finales Training mit besten Parametern"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "493727e8ae18f7d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), **best_params)\n",
    "for epoch in range(1, 31):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, _ = model(data.x, data.edge_index, data.edge_attr)\n",
    "        loss = criterion(out.view(-1), data.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-26T17:47:39.267227Z"
    }
   },
   "id": "a8491abb64b1774"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. üîÆ Autoregressive Forecast f√ºr 2024"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a0afe92fa89ac13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Beginne mit dem letzten Monat von 2023\n",
    "current_graph = val_list[-1].clone().to(device)\n",
    "hidden = None\n",
    "forecasts = []\n",
    "for i in range(12):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out, hidden = model(current_graph.x, current_graph.edge_index, current_graph.edge_attr, hidden)\n",
    "    forecasts.append(out.cpu())\n",
    "    # Update f√ºr n√§chsten Monat\n",
    "    new_edge_attr = torch.cat([current_graph.edge_attr.cpu(), out.unsqueeze(1)], dim=1)\n",
    "    new_edge_attr = torch.cat([new_edge_attr[:,:3], new_edge_attr[:,4:]], dim=1)\n",
    "    current_graph.edge_attr = new_edge_attr.to(device)\n",
    "    current_graph.y = out.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-26T17:47:39.270529Z"
    }
   },
   "id": "81aedb3cdcc6d222"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. üíæ Ergebnisse speichern"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e4955f806ac0e21"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.DataFrame([f.numpy() for f in forecasts]).T\n",
    "df.columns = [f'Month_{i+1}' for i in range(12)]\n",
    "df.to_csv('forecasts_2024.csv', index=False)\n",
    "print('Forecasts gespeichert als forecasts_2024.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-26T17:47:39.272103Z"
    }
   },
   "id": "f9492a66c567c10c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
