{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5cdb63",
   "metadata": {},
   "source": [
    "## Create Training and Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f5af4f",
   "metadata": {},
   "source": [
    "### Importing Dependencies\n",
    "\n",
    "We import the necessary libraries and functions, ensuring that all required modules and helper functions are properly integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514b8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import sys\n",
    "import torch\n",
    "import import_ipynb \n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from utils.wrapper.transform_networkx_into_pyg import transform_networkx_into_pyg\n",
    "from utils.helper_functions.add_dummy_node_features import add_dummy_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde60ae",
   "metadata": {},
   "source": [
    "### Loading and Preparing Graph Data from GraphML Files\n",
    "\n",
    "The `load_graphml_file` function loads a series of bicycle traffic network graphs stored in GraphML format and prepares them for training with PyTorch Geometric (PyG). The objective is to convert each monthly graph into a format compatible with Graph Neural Networks (GNNs), ensuring that edge features are retained.\n",
    "\n",
    "Each NetworkX graph is converted into a PyG `Data` object using a custom helper function `networkx_to_pyg`. This function ensures that essential edge attributes such as:\n",
    "\n",
    "- `tracks` (the number of bicycles traveling from the starting to the ending point),\n",
    "- `month` and `year`,\n",
    "- `speed_rel` (relative speed),\n",
    "\n",
    "are preserved during the conversion process.\n",
    "\n",
    "PyG expects data in a specific structure, particularly when edge attributes are used in models like GATv2.\n",
    "\n",
    "`data_list` contains multiple `torch_geometric.data.Data` objects, each representing a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d326e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphml_files(years=[2021, 2022, 2023]):\n",
    "    \"\"\"\n",
    "    Loads multiple directed graph files in GraphML format and converts them \n",
    "    into PyTorch Geometric (PyG) Data objects.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    years : list of int, optional (default=[2021, 2022, 2023])\n",
    "        List of years for which graph files should be loaded. \n",
    "        Assumes 12 monthly files per year.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data_list : list of torch_geometric.data.Data\n",
    "        List of PyG data objects created from the loaded NetworkX graphs.\n",
    "    \"\"\"\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for year in years:\n",
    "        for i in range(12):\n",
    "            path = f\"../../../data/graphml/{year}/bike_network_{year}_{i}.graphml\"\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"[WARN] File not found: {path}\")\n",
    "                continue\n",
    "\n",
    "            G_nx = nx.read_graphml(path)\n",
    "            G_nx = nx.DiGraph(G_nx)\n",
    "\n",
    "            data = transform_networkx_into_pyg(G_nx)\n",
    "            data_list.append(data)\n",
    "\n",
    "    print(f\"Number of loaded graphs: {len(data_list)}\")\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896be71",
   "metadata": {},
   "source": [
    "### Adding Dummy Node Features to the Graphs\n",
    "\n",
    "In this section of the code, we add **dummy node features** to our graphs. This process ensures that each node in our graphs has a **feature dimension**, even if no node features were originally present. This is an important step in preparing the data for use in Graph Neural Networks (GNNs).\n",
    "\n",
    "**NOTE:** At a later stage, once we have implemented feature engineering, we will replace the dummy features with the engineered ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3550c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(data_list, feature_dim=1, value=1.0):\n",
    "    # add dummy feature\n",
    "    return add_dummy_node_features(data_list, feature_dim=feature_dim, value=value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c609a6",
   "metadata": {},
   "source": [
    "### Train-Validation Split\n",
    "\n",
    "For predicting edge attributes (e.g., `tracks`), an 80/20 train/validation split is applied to the **existing edges within each graph**.\n",
    "\n",
    "In our application, the **nodes represent physically existing bike stations**, which typically do not change or only change very infrequently. The aim of the analysis is to model the **connections between stations**, i.e., to understand and predict how many bicycles move along certain routes (in other words: edges with weights).\n",
    "\n",
    "A **node-level split** (i.e., an 80/20 split of the nodes themselves) would mean that some stations would be completely unseen during training. This would not be meaningful because:\n",
    "\n",
    "- The **stations themselves are not the prediction target**;\n",
    "- It is the **relationships or transitions between the stations (edges)** that should be modeled;\n",
    "- In deployment, **all stations are known** (they are physically installed in the system);\n",
    "\n",
    "Initially, we wanted to use the `RandomLinkSplit()` function, but this is designed for classic link prediction â€“ i.e., binary classification. It adds both positive examples (existing edges) AND negative examples (non-existing edges). Since our task is an edge attribute regression task, this method is unsuitable, and we manually implemented the split mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8119f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(data_list, val_ratio=0.2, seed=42, save_dir=\"../../../data/data_splits\", edge_attr_key_index=4):\n",
    "    \"\"\"\n",
    "    Splits a list of PyTorch Geometric Data objects into training and validation sets\n",
    "    for edge regression tasks.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_list : list of torch_geometric.data.Data\n",
    "        List of graphs to be split into train and validation sets.\n",
    "    \n",
    "    val_ratio : float, optional (default=0.2)\n",
    "        Proportion of edges to be used for validation in each graph.\n",
    "    \n",
    "    seed : int, optional (default=42)\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    save_dir : str, optional (default='../../../data/data_splits')\n",
    "        Directory path where the split datasets will be saved.\n",
    "\n",
    "    edge_attr_key_index : int, optional (default=4)\n",
    "        The index of the edge attribute that should be predicted (e.g. 'tracks').\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    train_save_path = os.path.join(save_dir, \"train_data.pt\")\n",
    "    val_save_path = os.path.join(save_dir, \"val_data.pt\")\n",
    "\n",
    "    train_list, val_list = [], []\n",
    "    total_train_edges = 0\n",
    "    total_val_edges = 0\n",
    "\n",
    "    for i, data in enumerate(data_list):\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "        num_edges = edge_index.size(1)\n",
    "        num_val = int(val_ratio * num_edges)\n",
    "        perm = torch.randperm(num_edges)\n",
    "\n",
    "        val_idx = perm[:num_val]\n",
    "        train_idx = perm[num_val:]\n",
    "\n",
    "        # Training Data\n",
    "        train_data = data.clone()\n",
    "        train_data.edge_index = edge_index[:, train_idx]\n",
    "        train_data.edge_attr = edge_attr[train_idx]\n",
    "        train_data.y = edge_attr[train_idx][:, edge_attr_key_index] \n",
    "\n",
    "        # Validation Data\n",
    "        val_data = data.clone()\n",
    "        val_data.edge_index = edge_index[:, val_idx]\n",
    "        val_data.edge_attr = edge_attr[val_idx]\n",
    "        val_data.y = edge_attr[val_idx][:, edge_attr_key_index]  \n",
    "\n",
    "        train_list.append(train_data)\n",
    "        val_list.append(val_data)\n",
    "\n",
    "        total_train_edges += train_data.edge_index.size(1)\n",
    "        total_val_edges += val_data.edge_index.size(1)\n",
    "\n",
    "        print(f\"Graph {i}: Train edges = {train_data.edge_index.size(1)}, Val edges = {val_data.edge_index.size(1)}\")\n",
    "\n",
    "    # Batch the split data\n",
    "    train_data = Batch.from_data_list(train_list)\n",
    "    val_data = Batch.from_data_list(val_list)\n",
    "\n",
    "    # Save\n",
    "    torch.save(train_data, train_save_path)\n",
    "    torch.save(val_data, val_save_path)\n",
    "\n",
    "    print(f\"\\nTotal train edges (batched): {total_train_edges}\")\n",
    "    print(f\"Total val edges   (batched): {total_val_edges}\")\n",
    "    print(f\"\\nTrain data saved to: {train_save_path}\")\n",
    "    print(f\"Val data saved to: {val_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034c184",
   "metadata": {},
   "source": [
    "### Executing the Pipeline for Creating Training and Validation Data\n",
    "\n",
    "This script defines a `main` function that orchestrates the entire pipeline for generating training and validation splits for Graph Neural Networks (GNNs). The previously defined functions are called sequentially to load the graph data, perform feature engineering(not yet), and perform the data split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1707a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded graphs: 36\n",
      "Graph 0: Train edges = 12952, Val edges = 3238\n",
      "Graph 1: Train edges = 15959, Val edges = 3989\n",
      "Graph 2: Train edges = 19904, Val edges = 4976\n",
      "Graph 3: Train edges = 20536, Val edges = 5134\n",
      "Graph 4: Train edges = 31279, Val edges = 7819\n",
      "Graph 5: Train edges = 38328, Val edges = 9582\n",
      "Graph 6: Train edges = 32741, Val edges = 8185\n",
      "Graph 7: Train edges = 30916, Val edges = 7728\n",
      "Graph 8: Train edges = 30703, Val edges = 7675\n",
      "Graph 9: Train edges = 21666, Val edges = 5416\n",
      "Graph 10: Train edges = 17965, Val edges = 4491\n",
      "Graph 11: Train edges = 16285, Val edges = 4071\n",
      "Graph 12: Train edges = 17178, Val edges = 4294\n",
      "Graph 13: Train edges = 17021, Val edges = 4255\n",
      "Graph 14: Train edges = 23511, Val edges = 5877\n",
      "Graph 15: Train edges = 25231, Val edges = 6307\n",
      "Graph 16: Train edges = 35055, Val edges = 8763\n",
      "Graph 17: Train edges = 41335, Val edges = 10333\n",
      "Graph 18: Train edges = 35775, Val edges = 8943\n",
      "Graph 19: Train edges = 33536, Val edges = 8384\n",
      "Graph 20: Train edges = 30407, Val edges = 7601\n",
      "Graph 21: Train edges = 28829, Val edges = 7207\n",
      "Graph 22: Train edges = 21957, Val edges = 5489\n",
      "Graph 23: Train edges = 15362, Val edges = 3840\n",
      "Graph 24: Train edges = 16671, Val edges = 4167\n",
      "Graph 25: Train edges = 17980, Val edges = 4494\n",
      "Graph 26: Train edges = 18066, Val edges = 4516\n",
      "Graph 27: Train edges = 22253, Val edges = 5563\n",
      "Graph 28: Train edges = 26821, Val edges = 6705\n",
      "Graph 29: Train edges = 38612, Val edges = 9652\n",
      "Graph 30: Train edges = 31458, Val edges = 7864\n",
      "Graph 31: Train edges = 30864, Val edges = 7716\n",
      "Graph 32: Train edges = 30796, Val edges = 7698\n",
      "Graph 33: Train edges = 24759, Val edges = 6189\n",
      "Graph 34: Train edges = 19477, Val edges = 4869\n",
      "Graph 35: Train edges = 14930, Val edges = 3732\n",
      "\n",
      "Total train edges (batched): 907118\n",
      "Total val edges   (batched): 226762\n",
      "\n",
      "Train data saved to: ../../../data/data_splits\\train_data.pt\n",
      "Val data saved to: ../../../data/data_splits\\val_data.pt\n"
     ]
    }
   ],
   "source": [
    "def main(years=[2021, 2022, 2023], save_dir=\"../../../data/data_splits\", val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Main pipeline for loading graph data, preprocessing it, and splitting into train/val sets.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    years : list of int, optional (default=[2021, 2022, 2023])\n",
    "        The years for which GraphML files will be loaded.\n",
    "\n",
    "    save_dir : str, optional (default='../../../data/data_splits')\n",
    "        Directory where the processed train and validation data will be saved.\n",
    "\n",
    "    val_ratio : float, optional (default=0.2)\n",
    "        Proportion of edges to be used for validation during the random link split.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = load_graphml_files(years)\n",
    "    data_list = add_features(data_list)\n",
    "    split_train_val(data_list, val_ratio=val_ratio, save_dir=save_dir)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
